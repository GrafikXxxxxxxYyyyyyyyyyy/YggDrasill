{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NoisePredictor model has successfully loaded from 'GrafikXxxxxxxYyyyyyyyyyy/sdxl_Juggernaut' checkpoint!\n",
      "VAE model has successfully loaded from 'GrafikXxxxxxxYyyyyyyyyyy/sdxl_Juggernaut' checkpoint!\n",
      "TextEncoder model has successfully loaded from 'GrafikXxxxxxxYyyyyyyyyyy/sdxl_Juggernaut' checkpoint!\n"
     ]
    }
   ],
   "source": [
    "from YggDrasill.stable_diffusion_model import StableDiffusionModel, StableDiffusionModelKey\n",
    "\n",
    "KEY = StableDiffusionModelKey()\n",
    "\n",
    "sd = StableDiffusionModel(**KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from YggDrasill.core.diffusion_pipeline import ForwardDiffusionInput\n",
    "from YggDrasill.stable_diffusion_pipeline import StableDiffusionPipeline, StableDiffusionPipelineInput, DiffusionPipelineInput, TextEncoderPipelineInput\n",
    "\n",
    "INPUT = StableDiffusionPipelineInput(\n",
    "    diffusion_input = DiffusionPipelineInput(\n",
    "        forward_input = ForwardDiffusionInput(\n",
    "            strength = 1.0,\n",
    "            num_inference_steps = 30,\n",
    "        )\n",
    "    ),\n",
    "    use_refiner = False,\n",
    "    guidance_scale = 5.0,\n",
    "    te_input = TextEncoderPipelineInput(\n",
    "        prompt=[\n",
    "            \"cat\",\n",
    "            \"dog\",\n",
    "        ],\n",
    "        # prompt_2=[\n",
    "        #     \"cat\",\n",
    "        #     \"dog\",\n",
    "        # ],\n",
    "        negative_prompt=[\n",
    "            \"\",\n",
    "            \"\",\n",
    "        ],\n",
    "        clip_skip=2,\n",
    "    )\n",
    ")\n",
    "\n",
    "sd_pipeline = StableDiffusionPipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StableDiffusionPipeline --->\n",
      "TextEncoderPipeline --->\n",
      "CLIPTextEncoderPipeline --->\n",
      "CLIPTextEncoderModel --->\n",
      "torch.Size([2, 77, 768])\n",
      "torch.Size([2, 77, 1280])\n",
      "torch.Size([2, 1280])\n",
      "CLIPTextEncoderPipeline --->\n",
      "CLIPTextEncoderModel --->\n",
      "torch.Size([4, 77, 768])\n",
      "torch.Size([4, 77, 1280])\n",
      "torch.Size([4, 1280])\n",
      "TextEncoderPipelineOutput(do_cfg=True, batch_size=2, clip_embeds_1=tensor([[[-3.0293e+00, -1.9863e+00,  3.7852e+00,  ...,  8.4570e-01,\n",
      "          -2.2168e+00, -1.0059e+00],\n",
      "         [-6.7444e-02,  1.4624e-01, -1.6309e-01,  ...,  2.1240e-01,\n",
      "           2.4463e-01,  4.0405e-02],\n",
      "         [-4.0771e-02,  1.7090e-01, -2.4170e-01,  ...,  1.8726e-01,\n",
      "           2.0361e-01,  1.0681e-02],\n",
      "         ...,\n",
      "         [ 1.7261e-01, -2.2437e-01, -5.0781e-02,  ..., -1.3879e-01,\n",
      "          -2.8305e-02, -1.7261e-01],\n",
      "         [ 1.7810e-01, -2.2607e-01, -4.1382e-02,  ..., -1.4868e-01,\n",
      "          -2.7390e-02, -1.7041e-01],\n",
      "         [ 1.9836e-01, -1.8311e-01, -8.9111e-03,  ..., -1.3940e-01,\n",
      "          -5.0507e-03, -2.4158e-01]],\n",
      "\n",
      "        [[-3.0293e+00, -1.9863e+00,  3.7852e+00,  ...,  8.4570e-01,\n",
      "          -2.2168e+00, -1.0059e+00],\n",
      "         [-6.7444e-02,  1.4624e-01, -1.6309e-01,  ...,  2.1240e-01,\n",
      "           2.4463e-01,  4.0405e-02],\n",
      "         [-4.0771e-02,  1.7090e-01, -2.4170e-01,  ...,  1.8726e-01,\n",
      "           2.0361e-01,  1.0681e-02],\n",
      "         ...,\n",
      "         [ 1.7261e-01, -2.2437e-01, -5.0781e-02,  ..., -1.3879e-01,\n",
      "          -2.8305e-02, -1.7261e-01],\n",
      "         [ 1.7810e-01, -2.2607e-01, -4.1382e-02,  ..., -1.4868e-01,\n",
      "          -2.7390e-02, -1.7041e-01],\n",
      "         [ 1.9836e-01, -1.8311e-01, -8.9111e-03,  ..., -1.3940e-01,\n",
      "          -5.0507e-03, -2.4158e-01]],\n",
      "\n",
      "        [[-3.0293e+00, -1.9863e+00,  3.7852e+00,  ...,  8.4570e-01,\n",
      "          -2.2168e+00, -1.0059e+00],\n",
      "         [ 1.0535e-01,  3.6304e-01,  2.9102e-01,  ..., -1.0732e+00,\n",
      "          -4.4922e-02, -3.8159e-01],\n",
      "         [ 2.7075e-01,  4.6826e-01,  2.4414e-03,  ..., -1.0480e-01,\n",
      "           2.7588e-01, -2.7588e-02],\n",
      "         ...,\n",
      "         [ 1.5894e-01, -1.4258e-01, -4.7424e-02,  ..., -1.2305e-01,\n",
      "          -3.9551e-02, -1.6663e-01],\n",
      "         [ 1.6577e-01, -1.4233e-01, -4.1382e-02,  ..., -1.3403e-01,\n",
      "          -4.0314e-02, -1.6284e-01],\n",
      "         [ 1.8311e-01, -1.0571e-01, -9.0332e-03,  ..., -1.3257e-01,\n",
      "          -1.9638e-02, -2.2461e-01]],\n",
      "\n",
      "        [[-3.0293e+00, -1.9863e+00,  3.7852e+00,  ...,  8.4570e-01,\n",
      "          -2.2168e+00, -1.0059e+00],\n",
      "         [-7.0996e-01,  3.4863e-01,  1.6150e-01,  ..., -3.4814e-01,\n",
      "          -4.8730e-01, -1.9092e-01],\n",
      "         [-6.6040e-02,  3.7354e-01,  1.8921e-02,  ..., -2.7783e-01,\n",
      "           2.9565e-01,  1.8811e-01],\n",
      "         ...,\n",
      "         [ 2.0703e-01, -1.7603e-01, -1.8921e-02,  ..., -1.9495e-01,\n",
      "          -5.6946e-02, -1.7261e-01],\n",
      "         [ 2.1436e-01, -1.7554e-01, -1.2512e-02,  ..., -2.0508e-01,\n",
      "          -5.9204e-02, -1.6919e-01],\n",
      "         [ 2.3218e-01, -1.3354e-01,  1.6541e-02,  ..., -1.9971e-01,\n",
      "          -3.0869e-02, -2.2852e-01]]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<CatBackward0>), clip_embeds_2=tensor([[[ 0.0730,  0.0488, -0.1987,  ...,  0.0208,  0.1013, -0.1583],\n",
      "         [ 0.9346,  0.2610,  0.5205,  ...,  0.2793, -0.4248,  0.2639],\n",
      "         [-0.1765, -0.2329, -0.6787,  ...,  0.0833,  0.1882, -0.1143],\n",
      "         ...,\n",
      "         [ 0.3433, -0.1660,  0.2046,  ..., -0.1757,  0.4368,  0.8511],\n",
      "         [ 0.2209, -0.1117,  0.2117,  ..., -0.2238,  0.3528,  0.8999],\n",
      "         [ 0.3389, -0.2161,  0.2068,  ..., -0.1917,  0.5737,  0.8818]],\n",
      "\n",
      "        [[ 0.0730,  0.0488, -0.1987,  ...,  0.0208,  0.1013, -0.1583],\n",
      "         [ 0.9346,  0.2610,  0.5205,  ...,  0.2793, -0.4248,  0.2639],\n",
      "         [-0.1765, -0.2329, -0.6787,  ...,  0.0833,  0.1882, -0.1143],\n",
      "         ...,\n",
      "         [ 0.3433, -0.1660,  0.2046,  ..., -0.1757,  0.4368,  0.8511],\n",
      "         [ 0.2209, -0.1117,  0.2117,  ..., -0.2238,  0.3528,  0.8999],\n",
      "         [ 0.3389, -0.2161,  0.2068,  ..., -0.1917,  0.5737,  0.8818]],\n",
      "\n",
      "        [[ 0.0730,  0.0488, -0.1987,  ...,  0.0208,  0.1013, -0.1583],\n",
      "         [ 1.1162,  0.4395,  1.3701,  ..., -0.1388,  1.0850,  0.7573],\n",
      "         [ 0.5840, -0.2245,  0.4973,  ..., -0.0424,  0.9937,  0.4409],\n",
      "         ...,\n",
      "         [ 0.4238, -0.1392,  0.2097,  ...,  0.0509,  0.5356,  0.7520],\n",
      "         [ 0.3147, -0.0823,  0.2274,  ...,  0.0017,  0.4512,  0.7969],\n",
      "         [ 0.4224, -0.2239,  0.2164,  ...,  0.0780,  0.6636,  0.7803]],\n",
      "\n",
      "        [[ 0.0730,  0.0488, -0.1987,  ...,  0.0208,  0.1013, -0.1583],\n",
      "         [ 0.5747,  1.0215,  0.7422,  ...,  0.0219,  0.4966, -0.1409],\n",
      "         [ 0.2876,  0.1368,  0.3542,  ...,  0.1110, -0.1193, -0.1681],\n",
      "         ...,\n",
      "         [ 0.3989, -0.2284,  0.4375,  ..., -0.0652,  0.5264,  0.7744],\n",
      "         [ 0.2769, -0.1959,  0.4590,  ..., -0.1152,  0.4458,  0.8140],\n",
      "         [ 0.3928, -0.3008,  0.4463,  ..., -0.0517,  0.6558,  0.8179]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<CatBackward0>), pooled_clip_embeds=tensor([[-0.4814,  0.7944, -0.7651,  ..., -1.0791, -1.0859,  1.0957],\n",
      "        [-0.4814,  0.7944, -0.7651,  ..., -1.0791, -1.0859,  1.0957],\n",
      "        [-0.3228, -0.0298,  0.5000,  ..., -1.2549, -1.1309, -0.5034],\n",
      "        [-0.9292,  0.5732,  0.4094,  ..., -1.9033, -1.1221, -0.2681]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<CatBackward0>), cross_attention_kwargs=None)\n"
     ]
    }
   ],
   "source": [
    "sd_pipeline(\n",
    "    # model = sd,\n",
    "    **INPUT,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
