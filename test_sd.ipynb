{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NoisePredictor model has successfully loaded from 'GrafikXxxxxxxYyyyyyyyyyy/sdxl_Juggernaut' checkpoint!\n",
      "VAE model has successfully loaded from 'GrafikXxxxxxxYyyyyyyyyyy/sdxl_Juggernaut' checkpoint!\n",
      "TextEncoder model has successfully loaded from 'GrafikXxxxxxxYyyyyyyyyyy/sdxl_Juggernaut' checkpoint!\n",
      "Scheduler has successfully changed to 'euler'\n"
     ]
    }
   ],
   "source": [
    "from YggDrasill.stable_diffusion_pipeline import StableDiffusionPipeline\n",
    "from YggDrasill.stable_diffusion_model import StableDiffusionModel, StableDiffusionModelKey\n",
    "\n",
    "KEY = StableDiffusionModelKey()\n",
    "\n",
    "sd_model = StableDiffusionModel(**KEY)\n",
    "sd_pipeline = StableDiffusionPipeline(**KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from YggDrasill.core.diffusion_pipeline import ForwardDiffusionInput\n",
    "from YggDrasill.stable_diffusion_pipeline import StableDiffusionPipelineInput, DiffusionPipelineInput, TextEncoderPipelineInput\n",
    "\n",
    "INPUT = StableDiffusionPipelineInput(\n",
    "    diffusion_input = DiffusionPipelineInput(\n",
    "        forward_input = ForwardDiffusionInput(\n",
    "            strength = 1.0,\n",
    "            num_inference_steps = 30,\n",
    "        )\n",
    "    ),\n",
    "    use_refiner = False,\n",
    "    guidance_scale = 5.0,\n",
    "    te_input = TextEncoderPipelineInput(\n",
    "        prompt=[\n",
    "            \"cat\",\n",
    "            \"dog\",\n",
    "        ],\n",
    "        # prompt_2=[\n",
    "        #     \"cat\",\n",
    "        #     \"dog\",\n",
    "        # ],\n",
    "        negative_prompt=[\n",
    "            \"\",\n",
    "            \"\",\n",
    "        ],\n",
    "        clip_skip=2,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StableDiffusionPipeline --->\n",
      "CLIPTextEncoderModel --->\n",
      "torch.Size([2, 77, 768])\n",
      "torch.Size([2, 77, 1280])\n",
      "torch.Size([2, 1280])\n",
      "CLIPTextEncoderModel --->\n",
      "torch.Size([4, 77, 768])\n",
      "torch.Size([4, 77, 1280])\n",
      "torch.Size([4, 1280])\n",
      "StableDiffusionModel --->\n",
      "ConditionsSDP after model: Conditions(class_labels=None, prompt_embeds=tensor([[[-3.0293e+00, -1.9863e+00,  3.7852e+00,  ...,  2.0813e-02,\n",
      "           1.0126e-01, -1.5833e-01],\n",
      "         [-6.7444e-02,  1.4624e-01, -1.6309e-01,  ...,  2.7930e-01,\n",
      "          -4.2480e-01,  2.6392e-01],\n",
      "         [-4.0771e-02,  1.7090e-01, -2.4170e-01,  ...,  8.3313e-02,\n",
      "           1.8823e-01, -1.1432e-01],\n",
      "         ...,\n",
      "         [ 1.7261e-01, -2.2437e-01, -5.0781e-02,  ..., -1.7566e-01,\n",
      "           4.3677e-01,  8.5107e-01],\n",
      "         [ 1.7810e-01, -2.2607e-01, -4.1382e-02,  ..., -2.2375e-01,\n",
      "           3.5278e-01,  8.9990e-01],\n",
      "         [ 1.9836e-01, -1.8311e-01, -8.9111e-03,  ..., -1.9165e-01,\n",
      "           5.7373e-01,  8.8184e-01]],\n",
      "\n",
      "        [[-3.0293e+00, -1.9863e+00,  3.7852e+00,  ...,  2.0813e-02,\n",
      "           1.0126e-01, -1.5833e-01],\n",
      "         [-6.7444e-02,  1.4624e-01, -1.6309e-01,  ...,  2.7930e-01,\n",
      "          -4.2480e-01,  2.6392e-01],\n",
      "         [-4.0771e-02,  1.7090e-01, -2.4170e-01,  ...,  8.3313e-02,\n",
      "           1.8823e-01, -1.1432e-01],\n",
      "         ...,\n",
      "         [ 1.7261e-01, -2.2437e-01, -5.0781e-02,  ..., -1.7566e-01,\n",
      "           4.3677e-01,  8.5107e-01],\n",
      "         [ 1.7810e-01, -2.2607e-01, -4.1382e-02,  ..., -2.2375e-01,\n",
      "           3.5278e-01,  8.9990e-01],\n",
      "         [ 1.9836e-01, -1.8311e-01, -8.9111e-03,  ..., -1.9165e-01,\n",
      "           5.7373e-01,  8.8184e-01]],\n",
      "\n",
      "        [[-3.0293e+00, -1.9863e+00,  3.7852e+00,  ...,  2.0813e-02,\n",
      "           1.0126e-01, -1.5833e-01],\n",
      "         [ 1.0535e-01,  3.6304e-01,  2.9102e-01,  ..., -1.3879e-01,\n",
      "           1.0850e+00,  7.5732e-01],\n",
      "         [ 2.7075e-01,  4.6826e-01,  2.4414e-03,  ..., -4.2358e-02,\n",
      "           9.9365e-01,  4.4092e-01],\n",
      "         ...,\n",
      "         [ 1.5894e-01, -1.4258e-01, -4.7424e-02,  ...,  5.0934e-02,\n",
      "           5.3564e-01,  7.5195e-01],\n",
      "         [ 1.6577e-01, -1.4233e-01, -4.1382e-02,  ...,  1.7090e-03,\n",
      "           4.5117e-01,  7.9688e-01],\n",
      "         [ 1.8311e-01, -1.0571e-01, -9.0332e-03,  ...,  7.8003e-02,\n",
      "           6.6357e-01,  7.8027e-01]],\n",
      "\n",
      "        [[-3.0293e+00, -1.9863e+00,  3.7852e+00,  ...,  2.0813e-02,\n",
      "           1.0126e-01, -1.5833e-01],\n",
      "         [-7.0996e-01,  3.4863e-01,  1.6150e-01,  ...,  2.1851e-02,\n",
      "           4.9658e-01, -1.4087e-01],\n",
      "         [-6.6040e-02,  3.7354e-01,  1.8921e-02,  ...,  1.1096e-01,\n",
      "          -1.1926e-01, -1.6809e-01],\n",
      "         ...,\n",
      "         [ 2.0703e-01, -1.7603e-01, -1.8921e-02,  ..., -6.5186e-02,\n",
      "           5.2637e-01,  7.7441e-01],\n",
      "         [ 2.1436e-01, -1.7554e-01, -1.2512e-02,  ..., -1.1523e-01,\n",
      "           4.4580e-01,  8.1396e-01],\n",
      "         [ 2.3218e-01, -1.3354e-01,  1.6541e-02,  ..., -5.1697e-02,\n",
      "           6.5576e-01,  8.1787e-01]]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<CatBackward0>), timestep_cond=None, attention_mask=None, cross_attention_kwargs=None, added_cond_kwargs={'text_embeds': tensor([[-0.4814,  0.7944, -0.7651,  ..., -1.0791, -1.0859,  1.0957],\n",
      "        [-0.4814,  0.7944, -0.7651,  ..., -1.0791, -1.0859,  1.0957],\n",
      "        [-0.3228, -0.0298,  0.5000,  ..., -1.2549, -1.1309, -0.5034],\n",
      "        [-0.9292,  0.5732,  0.4094,  ..., -1.9033, -1.1221, -0.2681]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<CatBackward0>)})\n",
      "ConditionsDP: None\n",
      "DiffusionModel --->\n",
      "ConditionsDP after model: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConditionsBD: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "NoisePredictor(dtype=torch.float16, device=device(type='cuda', index=0), model_type='sdxl', model_path='GrafikXxxxxxxYyyyyyyyyyy/sdxl_Juggernaut') argument after ** must be a mapping, not NoneType",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43msd_pipeline\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msd_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mINPUT\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/dev/YggDrasill/stable_diffusion_pipeline.py:77\u001b[0m, in \u001b[0;36mStableDiffusionPipeline.__call__\u001b[0;34m(self, model, diffusion_input, te_input, use_refiner, guidance_scale, aesthetic_score, negative_aesthetic_score, **kwargs)\u001b[0m\n\u001b[1;32m     75\u001b[0m diffusion_input\u001b[38;5;241m.\u001b[39mconditions \u001b[38;5;241m=\u001b[39m conditions\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2. Учитывая переданные аргументы, используем полученный/ые пайплайны\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 77\u001b[0m     diffusion_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdiffusion_process\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdiffuser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     79\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdiffusion_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/dev/YggDrasill/core/diffusion_pipeline.py:147\u001b[0m, in \u001b[0;36mDiffusionPipeline.diffusion_process\u001b[0;34m(self, diffuser, batch_size, width, height, conditions, image, generator, mask_image, forward_input, **kwargs)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, t \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28menumerate\u001b[39m(forward_output\u001b[38;5;241m.\u001b[39mtimesteps)):\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;66;03m# TODO: Добавить расширение условий за счёт ControlNet\u001b[39;00m\n\u001b[1;32m    144\u001b[0m     \u001b[38;5;66;03m# <...>\u001b[39;00m\n\u001b[1;32m    146\u001b[0m     backward_input\u001b[38;5;241m.\u001b[39mtimestep \u001b[38;5;241m=\u001b[39m t\n\u001b[0;32m--> 147\u001b[0m     backward_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdiffuser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredictor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mbackward_input\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;66;03m# TODO: Добавить обработку маски через image\u001b[39;00m\n\u001b[1;32m    153\u001b[0m     \u001b[38;5;66;03m# в случае если модель не для inpainting\u001b[39;00m\n\u001b[1;32m    156\u001b[0m images, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpre_post_process(\n\u001b[1;32m    157\u001b[0m     vae\u001b[38;5;241m=\u001b[39mdiffuser\u001b[38;5;241m.\u001b[39mvae,\n\u001b[1;32m    158\u001b[0m     latents\u001b[38;5;241m=\u001b[39mbackward_input\u001b[38;5;241m.\u001b[39mnoisy_sample,\n\u001b[1;32m    159\u001b[0m )\n",
      "File \u001b[0;32m~/dev/YggDrasill/core/pipelines/backward_diffusion.py:60\u001b[0m, in \u001b[0;36mBackwardDiffusion.backward_step\u001b[0;34m(self, predictor, timestep, noisy_sample, conditions, **kwargs)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConditionsBD: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconditions\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     59\u001b[0m \u001b[38;5;66;03m# Получаем предсказание шума\u001b[39;00m\n\u001b[0;32m---> 60\u001b[0m noise_predict \u001b[38;5;241m=\u001b[39m predictor(\n\u001b[1;32m     61\u001b[0m     timestep\u001b[38;5;241m=\u001b[39mtimestep,\n\u001b[1;32m     62\u001b[0m     noisy_sample\u001b[38;5;241m=\u001b[39mmodel_input,\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconditions,\n\u001b[1;32m     64\u001b[0m )\n\u001b[1;32m     66\u001b[0m \u001b[38;5;66;03m# Учитываем CFG\u001b[39;00m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdo_cfg:\n",
      "\u001b[0;31mTypeError\u001b[0m: NoisePredictor(dtype=torch.float16, device=device(type='cuda', index=0), model_type='sdxl', model_path='GrafikXxxxxxxYyyyyyyyyyy/sdxl_Juggernaut') argument after ** must be a mapping, not NoneType"
     ]
    }
   ],
   "source": [
    "sd_pipeline(\n",
    "    model = sd_model,\n",
    "    **INPUT,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
